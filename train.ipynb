{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843a8214",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47364568",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\admin\\miniconda3\\envs\\deepfake-detection\\Lib\\site-packages\\torchvision\\io\\image.py:14: UserWarning: Failed to load image Python extension: 'Could not load this library: C:\\Users\\admin\\miniconda3\\envs\\deepfake-detection\\Lib\\site-packages\\torchvision\\image.pyd'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os, sys\n",
    "from src.model import MFMViT\n",
    "from src.fft_utils import *\n",
    "from src.loss import MFMLoss\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77d0f8",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4200828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50:   0%|          | 0/5014 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[MFMViT init] embed_dim=768, num_patches=196, patches_per_side=14, patch_size=16, patch_dim=768\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 5014/5014 [13:44<00:00,  6.08it/s, loss=0.2955]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 0.3249 | Val Loss: 0.2959 | LR: 4.00e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 5014/5014 [13:44<00:00,  6.08it/s, loss=0.2622]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 0.2827 | Val Loss: 0.2685 | LR: 6.00e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 5014/5014 [14:08<00:00,  5.91it/s, loss=0.2437]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 0.2565 | Val Loss: 0.2450 | LR: 8.00e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 5014/5014 [13:49<00:00,  6.04it/s, loss=0.2215]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 0.2375 | Val Loss: 0.2276 | LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 5014/5014 [13:57<00:00,  5.99it/s, loss=0.2167]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 0.2236 | Val Loss: 0.2156 | LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 5014/5014 [13:51<00:00,  6.03it/s, loss=0.2075]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 0.2120 | Val Loss: 0.2076 | LR: 9.99e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 5014/5014 [13:47<00:00,  6.06it/s, loss=0.1942]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 0.2043 | Val Loss: 0.2009 | LR: 9.95e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 5014/5014 [13:46<00:00,  6.07it/s, loss=0.1868]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 0.1985 | Val Loss: 0.1947 | LR: 9.89e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50:  56%|█████▌    | 2788/5014 [07:42<05:54,  6.27it/s, loss=0.1973]"
     ]
    }
   ],
   "source": [
    "def trainer():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    img_size = 224\n",
    "    batch_size = 16\n",
    "    lr = 1e-4\n",
    "    epochs = 50\n",
    "    mask_ratio = 0.5\n",
    "    warmup_epochs = 5\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder('E:/data/train', transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    val_dataset = datasets.ImageFolder('E:/data/val', transform=transform) if os.path.exists('E:/data/val') else None\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) if val_dataset else None\n",
    "    \n",
    "    model = MFMViT(img_size=img_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = MFMLoss().to(device)\n",
    "    \n",
    "    warmup_scheduler = LambdaLR(optimizer, lambda epoch: min(1.0, (epoch + 1) / warmup_epochs))\n",
    "    cosine_scheduler = CosineAnnealingLR(optimizer, T_max=epochs - warmup_epochs, eta_min=1e-6)\n",
    "    \n",
    "    os.makedirs('checkpoints', exist_ok=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        train_loss = 0\n",
    "        \n",
    "        for images, _ in pbar:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            fft_original = apply_fft(images)\n",
    "            amplitude_original = get_spectrum_amplitude(fft_original)\n",
    "            \n",
    "            mask = get_mask(images.shape[0], images.shape[1], img_size, \n",
    "                          ratio=mask_ratio, device=device)\n",
    "            fft_masked = fft_original * mask\n",
    "            \n",
    "            corrupted_spatial = apply_ifft(fft_masked)\n",
    "            predicted_spatial = model(corrupted_spatial)\n",
    "            \n",
    "            fft_predicted = apply_fft(predicted_spatial)\n",
    "            amplitude_predicted = get_spectrum_amplitude(fft_predicted)\n",
    "            \n",
    "            loss = criterion(amplitude_predicted, amplitude_original, mask)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        val_loss = 0\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for images, _ in val_loader:\n",
    "                    images = images.to(device)\n",
    "                    \n",
    "                    fft_original = apply_fft(images)\n",
    "                    amplitude_original = get_spectrum_amplitude(fft_original)\n",
    "                    \n",
    "                    mask = get_mask(images.shape[0], images.shape[1], img_size, \n",
    "                                  ratio=mask_ratio, device=device)\n",
    "                    fft_masked = fft_original * mask\n",
    "                    \n",
    "                    corrupted_spatial = apply_ifft(fft_masked)\n",
    "                    predicted_spatial = model(corrupted_spatial)\n",
    "                    \n",
    "                    fft_predicted = apply_fft(predicted_spatial)\n",
    "                    amplitude_predicted = get_spectrum_amplitude(fft_predicted)\n",
    "                    \n",
    "                    loss = criterion(amplitude_predicted, amplitude_original, mask)\n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "        \n",
    "        if epoch < warmup_epochs:\n",
    "            warmup_scheduler.step()\n",
    "        else:\n",
    "            cosine_scheduler.step()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        msg = f'Epoch {epoch+1} | Train Loss: {train_loss:.4f}'\n",
    "        if val_loader:\n",
    "            msg += f' | Val Loss: {val_loss:.4f}'\n",
    "        msg += f' | LR: {optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "        print(msg + '\\n')\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), f'checkpoints/mfm_vit_epoch_{epoch+1}.pth')\n",
    "    \n",
    "    torch.save(model.state_dict(), 'checkpoints/mfm_vit_final.pth')\n",
    "    print('Training complete!')\n",
    "\n",
    "trainer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "143e0e53",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
