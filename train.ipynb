{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "843a8214",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "47364568",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import os, sys\n",
    "from src.model import MFMViT\n",
    "from src.fft_utils import *\n",
    "from tqdm import tqdm\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, LambdaLR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd77d0f8",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4200828",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1/50: 100%|██████████| 1336/1336 [04:00<00:00,  5.56it/s, loss=13338.3438]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 | Train Loss: 19044.708215 | Val Loss: 14770.454159 | LR: 4.00e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2/50: 100%|██████████| 1336/1336 [03:56<00:00,  5.65it/s, loss=5773.7368] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2 | Train Loss: 9070.880006 | Val Loss: 6994.413939 | LR: 6.00e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3/50: 100%|██████████| 1336/1336 [03:56<00:00,  5.65it/s, loss=7941.4077]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3 | Train Loss: 6611.652681 | Val Loss: 6141.730342 | LR: 8.00e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4/50: 100%|██████████| 1336/1336 [03:56<00:00,  5.64it/s, loss=5669.5781]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4 | Train Loss: 6164.645501 | Val Loss: 5918.572889 | LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5/50: 100%|██████████| 1336/1336 [03:56<00:00,  5.64it/s, loss=6473.7642]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5 | Train Loss: 5883.975444 | Val Loss: 5733.585936 | LR: 1.00e-04\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6/50: 100%|██████████| 1336/1336 [03:56<00:00,  5.64it/s, loss=5392.1001]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6 | Train Loss: 5521.145441 | Val Loss: 5430.275198 | LR: 9.99e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7/50: 100%|██████████| 1336/1336 [04:00<00:00,  5.56it/s, loss=4564.3965]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7 | Train Loss: 5300.154755 | Val Loss: 5256.009271 | LR: 9.95e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8/50: 100%|██████████| 1336/1336 [03:55<00:00,  5.68it/s, loss=5367.5708]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8 | Train Loss: 5076.746818 | Val Loss: 5107.836536 | LR: 9.89e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9/50: 100%|██████████| 1336/1336 [03:51<00:00,  5.78it/s, loss=4244.1450]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9 | Train Loss: 4951.064136 | Val Loss: 4984.596456 | LR: 9.81e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10/50: 100%|██████████| 1336/1336 [03:53<00:00,  5.72it/s, loss=5073.7515]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10 | Train Loss: 4788.882865 | Val Loss: 4778.858478 | LR: 9.70e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11/50: 100%|██████████| 1336/1336 [03:54<00:00,  5.71it/s, loss=4509.7305]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11 | Train Loss: 4654.297732 | Val Loss: 4686.558941 | LR: 9.57e-05\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12/50: 100%|██████████| 1336/1336 [04:00<00:00,  5.56it/s, loss=4454.1284]\n"
     ]
    }
   ],
   "source": [
    "def trainer():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    img_size = 224\n",
    "    batch_size = 16\n",
    "    lr = 1e-4\n",
    "    epochs = 50\n",
    "    mask_ratio = 0.5\n",
    "    warmup_epochs = 5\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((img_size, img_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                           std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    train_dataset = datasets.ImageFolder('E:/data/train', transform=transform)\n",
    "    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Validation dataset (if exists)\n",
    "    val_dataset = datasets.ImageFolder('E:/data/val', transform=transform) if os.path.exists('E:/data/val') else None\n",
    "    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False) if val_dataset else None\n",
    "    \n",
    "    model = MFMViT(img_size=img_size).to(device)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    criterion = nn.MSELoss()\n",
    "    \n",
    "    warmup_scheduler = LambdaLR(optimizer, lambda epoch: min(1.0, (epoch + 1) / warmup_epochs))\n",
    "    cosine_scheduler = CosineAnnealingLR(optimizer, T_max=epochs - warmup_epochs, eta_min=1e-6)\n",
    "    \n",
    "    os.makedirs('checkpoints', exist_ok=True)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Training\n",
    "        model.train()\n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        train_loss = 0\n",
    "        \n",
    "        for images, _ in pbar:\n",
    "            images = images.to(device)\n",
    "            \n",
    "            fft_original = apply_fft(images)\n",
    "            amplitude_original = get_spectrum_amplitude(fft_original)\n",
    "            \n",
    "            mask = get_mask(images.shape[0], images.shape[1], img_size, \n",
    "                          ratio=mask_ratio, device=device)\n",
    "            fft_masked = fft_original * mask\n",
    "            \n",
    "            corrupted_spatial = apply_ifft(fft_masked)\n",
    "            predicted_spatial = model(corrupted_spatial)\n",
    "            \n",
    "            fft_predicted = apply_fft(predicted_spatial)\n",
    "            amplitude_predicted = get_spectrum_amplitude(fft_predicted)\n",
    "            \n",
    "            loss = criterion(amplitude_predicted * mask, amplitude_original * mask)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}'})\n",
    "        \n",
    "        # Validation\n",
    "        val_loss = 0\n",
    "        if val_loader:\n",
    "            model.eval()\n",
    "            with torch.no_grad():\n",
    "                for images, _ in val_loader:\n",
    "                    images = images.to(device)\n",
    "                    \n",
    "                    fft_original = apply_fft(images)\n",
    "                    amplitude_original = get_spectrum_amplitude(fft_original)\n",
    "                    \n",
    "                    mask = get_mask(images.shape[0], images.shape[1], img_size, \n",
    "                                  ratio=mask_ratio, device=device)\n",
    "                    fft_masked = fft_original * mask\n",
    "                    \n",
    "                    corrupted_spatial = apply_ifft(fft_masked)\n",
    "                    predicted_spatial = model(corrupted_spatial)\n",
    "                    \n",
    "                    fft_predicted = apply_fft(predicted_spatial)\n",
    "                    amplitude_predicted = get_spectrum_amplitude(fft_predicted)\n",
    "                    \n",
    "                    loss = criterion(amplitude_predicted * mask, amplitude_original * mask)\n",
    "                    val_loss += loss.item()\n",
    "            \n",
    "            val_loss /= len(val_loader)\n",
    "        \n",
    "        if epoch < warmup_epochs:\n",
    "            warmup_scheduler.step()\n",
    "        else:\n",
    "            cosine_scheduler.step()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        msg = f'Epoch {epoch+1} | Train Loss: {train_loss:.6f}'\n",
    "        if val_loader:\n",
    "            msg += f' | Val Loss: {val_loss:.6f}'\n",
    "        msg += f' | LR: {optimizer.param_groups[0][\"lr\"]:.2e}'\n",
    "        print(msg + '\\n')\n",
    "        \n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            torch.save(model.state_dict(), f'checkpoints/mfm_vit_epoch_{epoch+1}.pth')\n",
    "    \n",
    "    torch.save(model.state_dict(), 'checkpoints/mfm_vit_final.pth')\n",
    "    print('Training complete!')\n",
    "\n",
    "trainer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fb05841",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
