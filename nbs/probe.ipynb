{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d3add28c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "from src.model import MFMViT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd09cd71",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision.models as models\n",
    "from torchvision import datasets, transforms\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b5f42aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder, transform, max_images=100):\n",
    "    images = []\n",
    "    files = glob.glob(f'{folder}/*.jpg') + glob.glob(f'{folder}/*.png')\n",
    "    for file in files[:max_images]:\n",
    "        img = Image.open(file).convert('RGB')\n",
    "        images.append(transform(img).unsqueeze(0))\n",
    "    return torch.cat(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "d9364ef2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_resnet_features(model, images, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        features = model(images.to(device))\n",
    "    return features.cpu().numpy()\n",
    "\n",
    "def extract_mfm_features(model, images, device):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        tokens = model.encoder(images.to(device))\n",
    "        features = tokens.mean(dim=1)\n",
    "    return features.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "71c61ec2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "647838ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "real_images = load_images_from_folder('E:/data/train/real', transform, 100)\n",
    "fake_images = load_images_from_folder('E:/data/train/fake', transform, 100)\n",
    "all_labels = np.array([0]*100 + [1]*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "308f5f7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (3): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (4): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (5): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): Bottleneck(\n",
       "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "    (2): Bottleneck(\n",
       "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Identity()\n",
       ")"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resnet = models.resnet50(pretrained=True)\n",
    "resnet.fc = torch.nn.Identity()  \n",
    "resnet.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a6fa3126",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mfm_model = MFMViT(img_size=224).to(device)\n",
    "mfm_model.load_state_dict(torch.load('../checkpoints/mfm_vit_final.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "0649706e",
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet_real = extract_resnet_features(resnet, real_images, device)\n",
    "resnet_fake = extract_resnet_features(resnet, fake_images, device)\n",
    "resnet_features = np.vstack([resnet_real, resnet_fake])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "50330871",
   "metadata": {},
   "outputs": [],
   "source": [
    "mfm_real = extract_mfm_features(mfm_model, real_images, device)\n",
    "mfm_fake = extract_mfm_features(mfm_model, fake_images, device)\n",
    "mfm_features = np.vstack([mfm_real, mfm_fake])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc282205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train & evaluate\n",
    "X_train_rn, X_test_rn, y_train, y_test = train_test_split(\n",
    "    resnet_features, all_labels, test_size=0.3, random_state=42, stratify=all_labels\n",
    ")\n",
    "X_train_mfm, X_test_mfm, _, _ = train_test_split(\n",
    "    mfm_features, all_labels, test_size=0.3, random_state=42, stratify=all_labels\n",
    ")\n",
    "\n",
    "clf_resnet = LogisticRegression(max_iter=1000).fit(X_train_rn, y_train)\n",
    "clf_mfm = LogisticRegression(max_iter=1000).fit(X_train_mfm, y_train)\n",
    "\n",
    "acc_resnet = accuracy_score(y_test, clf_resnet.predict(X_test_rn))\n",
    "acc_mfm = accuracy_score(y_test, clf_mfm.predict(X_test_mfm))\n",
    "\n",
    "# Visualize\n",
    "plt.figure(figsize=(8, 5))\n",
    "bars = plt.bar(['ResNet50\\n(ImageNet)', 'MFM ViT\\n(Frequency)'], \n",
    "               [acc_resnet, acc_mfm], color=['#3498db', '#e74c3c'], alpha=0.7)\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.title('Linear Probing: ResNet vs MFM ViT\\n(100 Real + 100 Fake)', fontsize=14)\n",
    "plt.axhline(0.5, color='gray', linestyle='--', alpha=0.5, label='Random')\n",
    "for bar, acc in zip(bars, [acc_resnet, acc_mfm]):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, acc + 0.02, \n",
    "             f'{acc:.1%}', ha='center', fontweight='bold', fontsize=12)\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.savefig('resnet_vs_mfm_comparison.png', dpi=300)\n",
    "plt.show()\n",
    "\n",
    "print(f\"\\n=== Linear Probing Results ===\")\n",
    "print(f\"ResNet50 (Pretrained): {acc_resnet:.1%}\")\n",
    "print(f\"MFM ViT (Your Model):  {acc_mfm:.1%}\")\n",
    "print(f\"Winner: {'ResNet50' if acc_resnet > acc_mfm else 'MFM ViT' if acc_mfm > acc_resnet else 'Tie'}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "1f53c600",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Real images loaded: 100\n",
      "Fake images loaded: 70\n",
      "ResNet features shape: (170, 2048)\n",
      "MFM features shape: (170, 768)\n",
      "\n",
      "ResNet50: 76.5%\n",
      "MFM ViT:  58.8%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Real images loaded: {len(real_images)}\")\n",
    "print(f\"Fake images loaded: {len(fake_images)}\")\n",
    "print(f\"ResNet features shape: {resnet_features.shape}\")\n",
    "print(f\"MFM features shape: {mfm_features.shape}\")\n",
    "\n",
    "# Fix labels to match actual count\n",
    "all_labels = np.array([0]*len(real_images) + [1]*len(fake_images))\n",
    "\n",
    "# Then train/test split\n",
    "X_train_rn, X_test_rn, y_train, y_test = train_test_split(\n",
    "    resnet_features, all_labels, test_size=0.3, random_state=42, stratify=all_labels\n",
    ")\n",
    "X_train_mfm, X_test_mfm, _, _ = train_test_split(\n",
    "    mfm_features, all_labels, test_size=0.3, random_state=42, stratify=all_labels\n",
    ")\n",
    "\n",
    "clf_resnet = LogisticRegression(max_iter=1000).fit(X_train_rn, y_train)\n",
    "clf_mfm = LogisticRegression(max_iter=1000).fit(X_train_mfm, y_train)\n",
    "\n",
    "acc_resnet = accuracy_score(y_test, clf_resnet.predict(X_test_rn))\n",
    "acc_mfm = accuracy_score(y_test, clf_mfm.predict(X_test_mfm))\n",
    "\n",
    "print(f\"\\nResNet50: {acc_resnet:.1%}\")\n",
    "print(f\"MFM ViT:  {acc_mfm:.1%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0177b554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Bar chart\n",
    "plt.subplot(1, 2, 1)\n",
    "models = ['ResNet50\\n(ImageNet)', 'MFM ViT\\n(Frequency)']\n",
    "accuracies = [0.765, 0.588]\n",
    "colors = ['#2ecc71', '#e74c3c']\n",
    "bars = plt.bar(models, accuracies, color=colors, alpha=0.7, edgecolor='black', linewidth=2)\n",
    "plt.ylim(0, 1)\n",
    "plt.ylabel('Accuracy', fontsize=12, fontweight='bold')\n",
    "plt.title('Linear Probing Comparison\\n(100 Real + 70 Fake)', fontsize=14, fontweight='bold')\n",
    "plt.axhline(0.5, color='gray', linestyle='--', alpha=0.5, label='Random Baseline')\n",
    "for bar, acc in zip(bars, accuracies):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, acc + 0.03, \n",
    "             f'{acc:.1%}', ha='center', fontsize=14, fontweight='bold')\n",
    "plt.legend()\n",
    "plt.grid(axis='y', alpha=0.3)\n",
    "\n",
    "# Summary text\n",
    "plt.subplot(1, 2, 2)\n",
    "summary_text = f\"\"\"\n",
    "LINEAR PROBING RESULTS\n",
    "{'='*30}\n",
    "\n",
    "ResNet50 (Pretrained):  76.5%\n",
    "MFM ViT (Your Model):   58.8%\n",
    "\n",
    "Performance Gap:        17.7%\n",
    "\n",
    "WINNER: ResNet50\n",
    "\n",
    "KEY INSIGHTS:\n",
    "• ResNet's ImageNet features \n",
    "  transfer better to deepfake \n",
    "  detection\n",
    "  \n",
    "• MFM's frequency-based features\n",
    "  show promise but need more \n",
    "  training data or fine-tuning\n",
    "  \n",
    "• Both beat random (50%)\n",
    "\"\"\"\n",
    "plt.text(0.1, 0.5, summary_text, fontsize=11, family='monospace',\n",
    "         verticalalignment='center', bbox=dict(boxstyle='round', \n",
    "         facecolor='wheat', alpha=0.3))\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('linear_probing_comparison.png', dpi=300, bbox_inches='tight')\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n✅ Comparison complete! ResNet50 wins with 76.5% vs 58.8%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "038df233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    Loaded pretrained checkpoint\n",
      "    Epoch 1 : Acc : 71.03\n",
      "\n",
      "    Loaded pretrained checkpoint\n",
      "    Epoch 2 : Acc : 84.77\n",
      "\n",
      "    Loaded pretrained checkpoint\n",
      "    Epoch 3 : Acc : 91.01\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append('E:/AIGI')\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "from src.model import MFMViT\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "\n",
    "def linear_probe():\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    \n",
    "    # Load pretrained model\n",
    "    model = MFMViT(img_size=224).to(device)\n",
    "    \n",
    "    # Load checkpoint if exists\n",
    "    checkpoint_path = 'E:/AIGI/checkpoints/mfm_vit_final.pth'\n",
    "    if os.path.exists(checkpoint_path):\n",
    "        model.load_state_dict(torch.load(checkpoint_path), strict=False)\n",
    "        print(\"Loaded pretrained checkpoint\")\n",
    "    else:\n",
    "        print(\"No checkpoint found, using random initialization\")\n",
    "    \n",
    "    # Freeze encoder\n",
    "    for param in model.encoder.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    # Add classification head (2 classes: real/fake)\n",
    "    num_classes = 2\n",
    "    classifier = nn.Linear(model.encoder.embed_dim, num_classes).to(device)\n",
    "    \n",
    "    # Transforms\n",
    "    transform_train = transforms.Compose([\n",
    "        transforms.RandomResizedCrop(224),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    transform_val = transforms.Compose([\n",
    "        transforms.Resize(256),\n",
    "        transforms.CenterCrop(224),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "    \n",
    "    # Dataset\n",
    "    train_dataset = datasets.ImageFolder('E:/data/train', transform=transform_train)\n",
    "    val_dataset = datasets.ImageFolder('E:/data/val', transform=transform_val)\n",
    "    \n",
    "    train_loader = DataLoader(train_dataset, batch_size=256, shuffle=True, num_workers=4)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=256, shuffle=False, num_workers=4)\n",
    "    \n",
    "    optimizer = optim.SGD(classifier.parameters(), lr=0.1, momentum=0.9, weight_decay=1e-4)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
    "    \n",
    "    epochs = 3\n",
    "    best_acc = 0\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        # Train\n",
    "        classifier.train()\n",
    "        model.encoder.eval()\n",
    "        train_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        pbar = tqdm(train_loader, desc=f'Epoch {epoch+1}/{epochs}')\n",
    "        for images, labels in pbar:\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            with torch.no_grad():\n",
    "                features = model.encoder(images)[:, 0]  # CLS token\n",
    "            \n",
    "            outputs = classifier(features)\n",
    "            loss = criterion(outputs, labels)\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            total += labels.size(0)\n",
    "            correct += predicted.eq(labels).sum().item()\n",
    "            \n",
    "            pbar.set_postfix({'loss': f'{loss.item():.4f}', 'acc': f'{100.*correct/total:.2f}%'})\n",
    "        \n",
    "        # Validation\n",
    "        classifier.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                features = model.encoder(images)[:, 0]\n",
    "                outputs = classifier(features)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        val_acc = 100. * val_correct / val_total\n",
    "        print(f'Epoch {epoch+1} | Acc: {100.*correct/total:.2f}')\n",
    "        \n",
    "        if val_acc > best_acc:\n",
    "            best_acc = val_acc\n",
    "            torch.save(classifier.state_dict(), 'checkpoints/linear_probe_best.pth')\n",
    "        \n",
    "        scheduler.step()\n",
    "    \n",
    "    print(f'Best Val Accuracy: {best_acc:.2f}%')\n",
    "\n",
    "linear_probe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2aae3b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c022d606",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "deepfake-detection",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
